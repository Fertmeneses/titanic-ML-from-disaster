# Titanic: Machine Learning from Disaster

Welcome to a **deep study** for the *Titanic - Machine Learning from Disaster* competition, hosted by **Kaggle**. You can find my original competition notebook in this [link](https://www.kaggle.com/code/fertmeneses/titanic-kaggle-full-analysis)üëàüèΩ.

## Introduction

The competition [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/overview) is hosted by the [Kaggle](https://www.kaggle.com/) platform. It is a great challenge to develop a Machine Learning algorithm able to predict who survived the Titanic disaster from a small dataset with limited information. The challenge focuses mainly in Data analysis, feature engineering, and the design of generally shallow Machine Learning architectures, given the size of the dataset.

My notebook is written in Python code along with detailed markdown that will guide you through the whole process. Functions inside the code include many parameters that give you a lot of freedom if you want to experiment.

The original competition dataset is the folder "titanic-input", while my results and additional resources are stored in the folder "titanic-fm". Finally, you can find the final submission file "submission.csv", with my best predictions. The score that I achieved in the competition was 79.904%, which is above the average results, between 77.25% and 77.75%.

## Dependencies

Python packages, sorted alphabetically:

* copy
* datetime
* IPython.display
* itertools
* matplotlib
* mpl_toolkits
* numpy
* os
* pandas
* seaborn
* sklearn
* termcolor
* warnings
* wordcloud
* xgboost

## Author

* Fernando Meneses.

Find more about me in: [kaggle](https://www.kaggle.com/fertmeneses), [LinkedIn](https://www.linkedin.com/in/fernando-meneses-unc/).

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.
