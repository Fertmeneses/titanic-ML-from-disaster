# Titanic: Machine Learning from Disaster

Python code and datasets for the Kaggle competition: Titanic - Machine Learning from Disaster.

## Description

The competition [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/overview) is hosted by the [Kaggle](https://www.kaggle.com/) platform. It is a great challenge to develop a Machine Learning algorithm able to predict who survived the Titanic disaster from a small dataset with limited information. The challenge focuses mainly in Data analysis, feature engineering, and the design of generally shallow Machine Learning architectures, given the size of the dataset.

My notebook is written in Python code along with detailed markdown that will guide you through the whole process. You can find it in the Kaggle platform in this link: [Titanic/Kaggle - Full analysis ðŸ•µ](https://www.kaggle.com/code/fertmeneses/titanic-kaggle-full-analysis/input). Functions inside the code include many parameters that give you a lot of freedom if you want to experiment.

The original competition dataset is the folder "titanic-input", while my results and additional resources are stored in the folder "titanic-fm". Finally, you can find the final submission file "submission.csv", with my best predictions. The score that I achieved in the competition was 79.904%, which is above the average results, between 77.25% and 77.75%.

## Getting Started

### Dependencies

Python packages, sorted alphabetically:

* copy
* datetime
* IPython.display
* itertools
* matplotlib
* mpl_toolkits
* numpy
* os
* pandas
* seaborn
* sklearn
* termcolor
* warnings
* wordcloud
* xgboost

## Authors

* Fernando Meneses.

Find more about me in: [kaggle](https://www.kaggle.com/fertmeneses), [LinkedIn](https://www.linkedin.com/in/fernando-meneses-unc/).

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.
